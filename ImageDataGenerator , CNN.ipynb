{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ccbe2c3",
   "metadata": {},
   "source": [
    "# cats vs dogs, Using ImageDataGenerator \n",
    "\n",
    "2 class (cats va dogs), \n",
    "each class 2000 image, each class 1000 image for train, 500 for validation, 500 for test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a38a8",
   "metadata": {},
   "source": [
    "### make dirctories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "67081e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "\n",
    "original_dataset_dir='./dogs-vs-cats' \n",
    "our_dataset_dir= './database'\n",
    "\n",
    "os.mkdir(our_dataset_dir)\n",
    "\n",
    "\n",
    "train_dir=os.path.join(our_dataset_dir,'train') \n",
    "validation_dir=os.path.join(our_dataset_dir,'validation') \n",
    "test_dir=os.path.join(our_dataset_dir,'test') \n",
    "\n",
    "os.mkdir(train_dir) \n",
    "os.mkdir(validation_dir) \n",
    "os.mkdir(test_dir)\n",
    "\n",
    "\n",
    "train_cats_dir=os.path.join(train_dir,'cats') \n",
    "train_dogs_dir=os.path.join(train_dir,'dogs') \n",
    "validation_cats_dir=os.path.join(validation_dir,'cats') \n",
    "validation_dogs_dir=os.path.join(validation_dir,'dogs') \n",
    "test_cats_dir=os.path.join(test_dir,'cats') \n",
    "test_dogs_dir=os.path.join(test_dir,'dogs') \n",
    "\n",
    "os.mkdir(train_cats_dir) \n",
    "os.mkdir(train_dogs_dir)\n",
    "os.mkdir(validation_cats_dir)\n",
    "os.mkdir(validation_dogs_dir)\n",
    "os.mkdir(test_cats_dir)\n",
    "os.mkdir(test_dogs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac02e12",
   "metadata": {},
   "source": [
    "### fill dirctories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "766a9232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  shutil \n",
    "\n",
    "\n",
    "fnames_cat_train=['cat.{}.jpg'.format(i) for i in range(1000)] \n",
    "for fname in fnames_cat_train:\n",
    "    src=os.path.join(original_dataset_dir, fname)\n",
    "    dst=os.path.join(train_cats_dir,fname)\n",
    "    shutil.copyfile(src,dst) \n",
    "    \n",
    "\n",
    "fnames_cat_validation=['cat.{}.jpg'.format(i) for i in range(1000, 1500)] \n",
    "for fname in fnames_cat_validation:\n",
    "    src=os.path.join(original_dataset_dir, fname)\n",
    "    dst=os.path.join(validation_cats_dir,fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "    \n",
    "fnames_cat_test=['cat.{}.jpg'.format(i) for i in range(1500, 2000)] \n",
    "for fname in fnames_cat_test:\n",
    "    src=os.path.join(original_dataset_dir, fname)\n",
    "    dst=os.path.join(test_cats_dir,fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "####################dog s part:\n",
    "\n",
    "fnames_dog_train=['dog.{}.jpg'.format(i) for i in range(1000)] \n",
    "for fname in fnames_dog_train:\n",
    "    src=os.path.join(original_dataset_dir, fname)\n",
    "    dst=os.path.join(train_dogs_dir,fname)\n",
    "    shutil.copyfile(src,dst) \n",
    "    \n",
    "\n",
    "fnames_dog_validation=['dog.{}.jpg'.format(i) for i in range(1000, 1500)] \n",
    "for fname in fnames_dog_validation:\n",
    "    src=os.path.join(original_dataset_dir, fname)\n",
    "    dst=os.path.join(validation_dogs_dir,fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "    \n",
    "fnames_dog_test=['dog.{}.jpg'.format(i) for i in range(1500, 2000)] \n",
    "for fname in fnames_dog_test:\n",
    "    src=os.path.join(original_dataset_dir, fname)\n",
    "    dst=os.path.join(test_dogs_dir,fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b94e8",
   "metadata": {},
   "source": [
    "###  sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1895bc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat image: 1000\n"
     ]
    }
   ],
   "source": [
    "print('total training cat image:', len(os.listdir(train_cats_dir))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(train_cats_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57cc105",
   "metadata": {},
   "source": [
    "# ImageDataGenerator class in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ImageDataGenerator:\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# step1: \n",
    "train_datagen=ImageDataGenerator(rescale=1./255) # \n",
    "\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# step2: \n",
    "train_generator= train_datagen.flow_from_directory(train_dir, \n",
    "                                                   target_size=(150,150), \n",
    "                                                   batch_size=20, \n",
    "                                                   class_mode='binary') # \n",
    "\n",
    "validation_generator= validation_datagen.flow_from_directory(validation_dir, \n",
    "                                                   target_size=(150,150),\n",
    "                                                   batch_size=20,\n",
    "                                                   class_mode='binary') #shuffel=True (defult), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "81fe9bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape:  (20, 150, 150, 3)\n",
      "labels batch shape:  (20,)\n"
     ]
    }
   ],
   "source": [
    "# calling  generator  ImageDataGenerator:\n",
    "\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape: ' , data_batch.shape) # (20, 150, 150, 3)\n",
    "    print('labels batch shape: ' , labels_batch.shape) # (20,)\n",
    "    break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b5e92e",
   "metadata": {},
   "source": [
    "# network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0461f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten()) \n",
    "model.add(layers.Dropout(0.5))  \n",
    "model.add(layers.Dense(512, activation='relu')) \n",
    "model.add(layers.Dense(1 , activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), \n",
    "                 loss='binary_crossentropy', \n",
    "                 metrics=['acc'])  # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c179efbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 74, 74, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 36, 36, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 17, 17, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf13ea1",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b01d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history=model.fit(train_generator, \n",
    "                    steps_per_epoch=100, #how many batches in each epoch, \n",
    "                    epochs=30, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=50) #how many batches for validation\n",
    "\n",
    "model.save('cats_vs_dogs_v1.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b05fd4a",
   "metadata": {},
   "source": [
    "# data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5dc1d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                          rotation_range=40, #  [-40 40] ,  rotation_range  (0 180)\n",
    "                          width_shift_range=0.2, #  [-0.2 0.2]\n",
    "                          height_shift_range=0.2,\n",
    "                          shear_range=0.2, \n",
    "                          zoom_range=0.2, #  [1-0.2  1+0.2] \n",
    "                          horizontal_flip=True, \n",
    "                          fill_mode='nearest')\n",
    "\n",
    "\n",
    "train_generator= train_datagen.flow_from_directory(train_dir, \n",
    "                                                   target_size=(150,150), \n",
    "                                                  batch_size=20, \n",
    "                                                  class_mode='binary') # \n",
    "\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "\n",
    "validation_generator= validation_datagen.flow_from_directory(validation_dir, \n",
    "                                                   target_size=(150,150),\n",
    "                                                  batch_size=20,\n",
    "                                                  class_mode='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c12bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "model_history=model.fit(train_generator,\n",
    "                  steps_per_epoch=100, \n",
    "                  epochs=30,\n",
    "                  validation_data=validation_generator, \n",
    "                  validation_steps=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5da742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overfit checking\n",
    "history_dict=model_history.history\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "loss_values_train=history_dict['loss'] #  loss  train\n",
    "loss_values_val=history_dict['val_loss'] #  loss validation\n",
    "\n",
    "epoches=range(1, len(loss_values_train)+1)\n",
    "\n",
    "plt.plot(epoches,loss_values_train, 'bo',label='training')\n",
    "plt.plot(epoches,loss_values_val,'r', label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189958c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
